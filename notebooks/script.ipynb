{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import csv\n",
    "import spacy\n",
    "from enum import Enum\n",
    "from spacy import displacy\n",
    "from spacy.symbols import PROPN, NOUN, CCONJ, ADP, VERB\n",
    "import numpy as np\n",
    "import speech_recognition as sr \n",
    "from scipy.sparse import csr_matrix\n",
    "from sknetwork.path import shortest_path\n",
    "\n",
    "from collections import defaultdict\n",
    "import functools\n",
    "import itertools\n",
    "\n",
    "currentPath = os.path.dirname(os.path.abspath(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Read 3148 go and back trips (1574 distinc trips) out of 1574 rows for 816 distinct train stations.\n"
     ]
    }
   ],
   "source": [
    "# Reading trips from csv file\n",
    "# Inspired from https://stackoverflow.com/a/12398967\n",
    "\n",
    "pathCount = 0\n",
    "timeTableFileName = os.path.join(currentPath, './data/timetables_edited.csv')\n",
    "\n",
    "# Create dictionary to associates a station name with an id\n",
    "trainStationNameToId = defaultdict(functools.partial(next, itertools.count()))\n",
    "\n",
    "with open(timeTableFileName, newline='', encoding='UTF-8') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "    # Set of the reading position (ignoring header line)\n",
    "    csvfile.seek(0)\n",
    "    next(reader)\n",
    "\n",
    "    # First reading to get the number different stations and init shape of trips object\n",
    "    for row in reader:\n",
    "        idxA = trainStationNameToId[row[1]]\n",
    "        idxB = trainStationNameToId[row[2]]\n",
    "    numberOfTrainstations = len(trainStationNameToId)\n",
    "    trips = np.zeros((numberOfTrainstations, numberOfTrainstations))\n",
    "\n",
    "    # Reset of the reading position (ignoring header line)\n",
    "    csvfile.seek(0)\n",
    "    next(reader)\n",
    "\n",
    "    # Reading data\n",
    "    for row in reader:\n",
    "        pathCount += 1 \n",
    "        idxA = trainStationNameToId[row[1]]\n",
    "        idxB = trainStationNameToId[row[2]]\n",
    "\n",
    "        # If trip already exist/has already be read, display message\n",
    "        indexTupple = (idxA, idxB) if idxA < idxB else (idxB, idxA)\n",
    "        if trips[indexTupple] != 0:\n",
    "            print(f\"Trip {row[1]} - {row[2]} with a distance of {row[3]} has already be read with a distance of {trips[indexTupple]}. Ignoring the new one.\")\n",
    "        else:\n",
    "            trips[indexTupple] = int(row[3])\n",
    "\n",
    "\n",
    "# Create dictionarry to map an id to its train station name\n",
    "trainStationIdToName = dict((id, name) for name, id in trainStationNameToId.items())\n",
    "\n",
    "# Make matrix symetrical as the trips are not directed but can be taken in both directions\n",
    "# Source from https://stackoverflow.com/a/42209263\n",
    "i_lower = np.tril_indices(numberOfTrainstations, -1)\n",
    "trips[i_lower] = trips.T[i_lower]\n",
    "\n",
    "# Creating Compressed Sparse Row (CSR) matrix to store and work more efficiently with only the trips\n",
    "tripGraph = csr_matrix(trips)\n",
    "\n",
    "print(f\"Read {tripGraph.getnnz()} go and back trips ({int(tripGraph.getnnz() / 2)} distinc trips) out of {pathCount} rows for {len(trainStationNameToId)} distinct train stations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trip:\n",
    "    def __init__(self, startStationId, endStationId, path, totalDuration):\n",
    "        self.startStationId = startStationId\n",
    "        self.endStationId = endStationId\n",
    "        self.path = path\n",
    "        if totalDuration is None:\n",
    "            self.totalDuration = None\n",
    "        else:\n",
    "            self.totalDuration = int(totalDuration)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Trip from {trainStationIdToName[self.startStationId]} to {trainStationIdToName[self.endStationId]} for a total duration of {self.totalDuration} minutes by this path: {self.pathToString()}\"\n",
    "\n",
    "    def pathToString(self):\n",
    "        string = \"\"\n",
    "        for i in range(len(self.path)):\n",
    "            if i > 0:\n",
    "                string = string + \" -> \"\n",
    "            string = string + trainStationIdToName[self.path[i]]\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#1 - Trip from Gare de Orléans to Gare de Paris-Austerlitz for a total duration of 75 minutes by this path: Gare de Orléans -> Gare de Paris-Austerlitz\n#2 - Trip from Gare de Paris-Est to Gare de Strasbourg for a total duration of 287 minutes by this path: Gare de Paris-Est -> Gare de Epernay -> Gare de Metz-Ville -> Gare de Strasbourg\n#3 - Could not find one or both station of the sub-trip\n#4 - Could not find one or both station of the sub-trip\n#5 - Trip from Gare de Mulhouse to Gare de Mulhouse for a total duration of 0 minutes by this path: Gare de Mulhouse -> Gare de Mulhouse\n"
     ]
    }
   ],
   "source": [
    "# Functions used to determine the shortest path between cities \n",
    "\n",
    "def getPathBetweenIds(trainStationStartIds: list, trainStationEndIds: list):\n",
    "    global tripGraph\n",
    "    paths = []\n",
    "    # If start array contains one element also contained in end array -> return path from/to the same station\n",
    "    for startId in trainStationStartIds:\n",
    "        if startId in trainStationEndIds:\n",
    "            return [int(startId), int(startId)]\n",
    "\n",
    "    # As shortest_path() does not support multiple sources and multiple targets at the same time, we'll iterate through all start points and manually concat the results\n",
    "    if(len(trainStationStartIds) > 1 and len(trainStationEndIds) > 1):\n",
    "        for trainStationEndId in trainStationEndIds:\n",
    "            results = shortest_path(tripGraph, sources=[int(i) for i in trainStationStartIds], targets=[int(trainStationEndId)], method='D')\n",
    "            for result in results:\n",
    "                if len(result) >= 2:\n",
    "                    paths.append(result)\n",
    "        return paths\n",
    "    else:\n",
    "        results = shortest_path(tripGraph, sources=[int(i) for i in trainStationStartIds], targets=[int(i) for i in trainStationEndIds], method='D')\n",
    "        for result in results:\n",
    "            if len(result) >= 2:\n",
    "                paths.append(result)\n",
    "        return paths\n",
    "\n",
    "def isCityMatchingKey(city: str, key: str):\n",
    "    return city.lower() in key.lower()\n",
    "\n",
    "def getPathBetweenCities(start: str, end: str):\n",
    "    trainStationStartIds = np.array([])\n",
    "    trainStationEndIds = np.array([])\n",
    "    \n",
    "    # Get all stations that contains the searched name\n",
    "    for key, value in trainStationNameToId.items():\n",
    "        if isCityMatchingKey(start, key):\n",
    "            trainStationStartIds = np.append(trainStationStartIds, value)\n",
    "        if isCityMatchingKey(end, key):\n",
    "            trainStationEndIds = np.append(trainStationEndIds, value)\n",
    "\n",
    "    if len(trainStationStartIds) > 0 and len(trainStationEndIds) > 0:\n",
    "        return getPathBetweenIds(trainStationStartIds, trainStationEndIds)\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "def getBestPathForFullTrip(tripCityWaypoints: list):\n",
    "    global tripGraph\n",
    "    fullTrip = np.array(np.zeros(len(tripCityWaypoints)-1), dtype=object)\n",
    "    # Iterate through all sub trips\n",
    "    for trip in range(len(fullTrip)):\n",
    "        paths = getPathBetweenCities(tripCityWaypoints[trip], tripCityWaypoints[trip+1])\n",
    "        minDistance = None\n",
    "        keptPath = None\n",
    "        startId = None\n",
    "        endId = None\n",
    "\n",
    "        # Iterate though the returned array\n",
    "        for path in paths:\n",
    "            distance = 0\n",
    "            # Nested array => multiple start/end possible\n",
    "            if isinstance(path, list):\n",
    "                for i in range(len(path)-1):\n",
    "                    distance = distance + tripGraph[(path[i], path[i+1])]\n",
    "                if minDistance is None or distance < minDistance:\n",
    "                    minDistance = distance\n",
    "                    keptPath = path\n",
    "                    startId = path[0]\n",
    "                    endId = path[len(path)-1]\n",
    "            \n",
    "            # Scalar value => only one path possible\n",
    "            else:\n",
    "                for i in range(len(paths)-1):\n",
    "                    distance = distance + tripGraph[(paths[i], paths[i+1])]\n",
    "                minDistance = distance\n",
    "                keptPath = paths\n",
    "                startId = paths[0]\n",
    "                endId = paths[len(paths)-1]\n",
    "\n",
    "        fullTrip[trip] = Trip(startId, endId, keptPath, minDistance)\n",
    "    return fullTrip\n",
    "\n",
    "\n",
    "# TEST\n",
    "# Use following to test pathfinding functions above\n",
    "def testPathfinding():\n",
    "    bestTrips = getBestPathForFullTrip(['Orléan', 'Paris', 'Strasbourg', 'dsfdsfd', 'Mulhouse', 'Mulhouse'])\n",
    "    for i in range(len(bestTrips)):\n",
    "        if bestTrips[i].path is not None:\n",
    "            print(f\"#{i+1} - {bestTrips[i]}\")\n",
    "        else:\n",
    "            if bestTrips[i].startStationId is None or bestTrips[i].endStationId is None:\n",
    "                print(f\"#{i+1} - Could not find one or both station of the sub-trip\")\n",
    "            else:\n",
    "                print(f\"#{i+1} - Could not find a path between the both stations\")\n",
    "testPathfinding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting user's request\n",
    "# Inspired from https://www.geeksforgeeks.org/python-convert-speech-to-text-and-text-to-speech/\n",
    "\n",
    "def recordUserRequest():\n",
    "    try: \n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source: \n",
    "            print(\"Adjusting to noise level...\")\n",
    "            r.adjust_for_ambient_noise(source, duration=0.2) \n",
    "    \n",
    "            print(\"Listening...\")\n",
    "            audio = r.listen(source) \n",
    "                \n",
    "            print(\"Voice recognition...\")\n",
    "            parsedUserRequest = r.recognize_google(audio, language=\"fr-FR\") \n",
    "\n",
    "            print(f\"Parsed: '{parsedUserRequest}'\")\n",
    "            return parsedUserRequest\n",
    "                \n",
    "    except sr.RequestError as e: \n",
    "        print(f\"Exception during request parsing: {e}\") \n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Request: Je veux partir de Mulhouse et visiter Paris depuis Strasbourg\n",
      "Locations found: ['Mulhouse', 'Paris', 'Strasbourg']\n",
      "Token #1 : Mulhouse\n",
      "Found ADP: de - STRONG - START\n",
      "Using: de\n",
      "---------------\n",
      "Token #2 : Paris\n",
      "Found VERB: visiter - STRONG - DEST\n",
      "Using: visiter\n",
      "---------------\n",
      "Token #3 : Strasbourg\n",
      "Found ADP: depuis - STRONG - START\n",
      "Found VERB: visiter - STRONG - DEST\n",
      "Using: depuis\n",
      "---------------\n",
      "Result trip: ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 0    ***************************\n",
      "result:    ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "exprected: ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: J'aimerais aller d'Orléans à Paris puis dans les Vosges\n",
      "Locations found: ['Orléans', 'Paris', 'Vosges']\n",
      "Token #1 : Orléans\n",
      "Found ADP: de - STRONG - START\n",
      "Found VERB: aller - STRONG - DEST\n",
      "Using: de\n",
      "---------------\n",
      "Token #2 : Paris\n",
      "Found ADP: à - WEAK - DEST\n",
      "Found VERB: aller - STRONG - DEST\n",
      "Using: aller\n",
      "---------------\n",
      "Token #3 : vosge\n",
      "Found CCONJ: puis - STRONG - DEST\n",
      "Using: puis\n",
      "---------------\n",
      "Result trip: ['Orléans', 'Paris', 'Vosges']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 1    ***************************\n",
      "result:    ['Orléans', 'Paris', 'Vosges']\n",
      "exprected: ['Orléans', 'Paris', 'Vosges']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux aller à Marseille à partir de Lyon\n",
      "Locations found: ['Marseille', 'Lyon']\n",
      "Token #1 : marseille\n",
      "Found ADP: à - WEAK - DEST\n",
      "Found VERB: aller - STRONG - DEST\n",
      "Using: aller\n",
      "---------------\n",
      "Token #2 : Lyon\n",
      "Found ADP: de - STRONG - START\n",
      "Using: de\n",
      "---------------\n",
      "Result trip: ['Lyon', 'Marseille']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 2    ***************************\n",
      "result:    ['Lyon', 'Marseille']\n",
      "exprected: ['Lyon', 'Marseille']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux visiter Paris en partant de Bordeaux et en passant par Nantes\n",
      "Locations found: ['Paris', 'Bordeaux', 'Nantes']\n",
      "Token #1 : Paris\n",
      "Found VERB: visiter - STRONG - DEST\n",
      "Using: visiter\n",
      "---------------\n",
      "Token #2 : bordeaux\n",
      "Found ADP: de - STRONG - START\n",
      "Using: de\n",
      "---------------\n",
      "Token #3 : nante\n",
      "Found ADP: par - WEAK - DEST\n",
      "Found VERB: passer - WEAK - START\n",
      "Using: par\n",
      "---------------\n",
      "Result trip: ['Bordeaux', 'Nantes', 'Paris']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 3    ***************************\n",
      "result:    ['Bordeaux', 'Nantes', 'Paris']\n",
      "exprected: ['Bordeaux', 'Nantes', 'Paris']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux prendre le train à Mulhouse à destination de Strasbourg\n",
      "Locations found: ['Mulhouse', 'Strasbourg']\n",
      "Token #1 : Mulhouse\n",
      "Found ADP: à - WEAK - DEST\n",
      "Using: à\n",
      "---------------\n",
      "Token #2 : Strasbourg\n",
      "Found NOUN: destination - WEAK - DEST\n",
      "Using: destination\n",
      "---------------\n",
      "Result trip: ['Mulhouse', 'Strasbourg']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 4    ***************************\n",
      "result:    ['Mulhouse', 'Strasbourg']\n",
      "exprected: ['Mulhouse', 'Strasbourg']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Strasbourg en provenance de Mulhouse\n",
      "Locations found: ['Strasbourg', 'Mulhouse']\n",
      "Token #1 : strasbourg\n",
      "Using default weight\n",
      "Using: default\n",
      "---------------\n",
      "Token #2 : Mulhouse\n",
      "Found NOUN: provenance - STRONG - START\n",
      "Using: provenance\n",
      "---------------\n",
      "Result trip: ['Mulhouse', 'Strasbourg']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 5    ***************************\n",
      "result:    ['Mulhouse', 'Strasbourg']\n",
      "exprected: ['Mulhouse', 'Strasbourg']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux aller de Mulhouse à Strasbourg\n",
      "Locations found: ['Mulhouse', 'Strasbourg']\n",
      "Token #1 : Mulhouse\n",
      "Found ADP: de - STRONG - START\n",
      "Found VERB: aller - STRONG - DEST\n",
      "Using: de\n",
      "---------------\n",
      "Token #2 : Strasbourg\n",
      "Found ADP: à - WEAK - DEST\n",
      "Found VERB: aller - STRONG - DEST\n",
      "Using: aller\n",
      "---------------\n",
      "Result trip: ['Mulhouse', 'Strasbourg']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 6    ***************************\n",
      "result:    ['Mulhouse', 'Strasbourg']\n",
      "exprected: ['Mulhouse', 'Strasbourg']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux faire Paris Gare De l'est Marseille\n",
      "Locations found: [\"Paris Gare De l'\", 'Marseille']\n",
      "Token #1 : Paris\n",
      "Using default weight\n",
      "Using: default\n",
      "---------------\n",
      "Token #2 : marseill\n",
      "Using default weight\n",
      "Using: default\n",
      "---------------\n",
      "Result trip: ['Paris', 'Marseille']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 7    ***************************\n",
      "result:    ['Paris', 'Marseille']\n",
      "exprected: ['Paris', 'Marseille']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux aller à Paris après être allé à Mulhouse depuis Lyon\n",
      "Locations found: ['Paris', 'Mulhouse', 'Lyon']\n",
      "Token #1 : Paris\n",
      "Found ADP: à - WEAK - DEST\n",
      "Found VERB: aller - STRONG - DEST\n",
      "Using: aller\n",
      "---------------\n",
      "Token #2 : Mulhouse\n",
      "Found ADP: à - WEAK - DEST\n",
      "Found VERB_MARK: après - WEAK - START\n",
      "Using: à\n",
      "---------------\n",
      "Token #3 : Lyon\n",
      "Found ADP: depuis - STRONG - START\n",
      "Found VERB_MARK: après - WEAK - START\n",
      "Using: depuis\n",
      "---------------\n",
      "Result trip: ['Lyon', 'Mulhouse', 'Paris']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 8    ***************************\n",
      "result:    ['Lyon', 'Mulhouse', 'Paris']\n",
      "exprected: ['Lyon', 'Mulhouse', 'Paris']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Paris-Marseille\n",
      "Locations found: ['Paris', 'Marseille']\n",
      "Token #1 : Paris\n",
      "Using default weight\n",
      "Using: default\n",
      "---------------\n",
      "Token #2 : Marseille\n",
      "Using default weight\n",
      "Using: default\n",
      "---------------\n",
      "Result trip: ['Paris', 'Marseille']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 9    ***************************\n",
      "result:    ['Paris', 'Marseille']\n",
      "exprected: ['Paris', 'Marseille']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je suis à Paris et je veux aller à Strasbourg avec mon amis Frank que je récupère à Mulhouse\n",
      "Locations found: ['Paris', 'Strasbourg', 'Mulhouse']\n",
      "Token #1 : Paris\n",
      "Found ADP: à - WEAK - DEST\n",
      "Using: à\n",
      "---------------\n",
      "Token #2 : Strasbourg\n",
      "Found ADP: à - WEAK - DEST\n",
      "Found VERB: aller - STRONG - DEST\n",
      "Using: aller\n",
      "---------------\n",
      "Token #3 : Mulhouse\n",
      "Found ADP: à - WEAK - DEST\n",
      "Using: à\n",
      "---------------\n",
      "Result trip: ['Paris', 'Mulhouse', 'Strasbourg']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 10    ***************************\n",
      "result:    ['Paris', 'Mulhouse', 'Strasbourg']\n",
      "exprected: ['Paris', 'Mulhouse', 'Strasbourg']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux voyager de Mulhouse pour visiter Paris en passant par Strasbourg\n",
      "Locations found: ['Mulhouse', 'Paris', 'Strasbourg']\n",
      "Token #1 : Mulhouse\n",
      "Found ADP: de - STRONG - START\n",
      "Found VERB: voyager - STRONG - DEST\n",
      "Using: de\n",
      "---------------\n",
      "Token #2 : Paris\n",
      "Found VERB: visiter - STRONG - DEST\n",
      "Using: visiter\n",
      "---------------\n",
      "Token #3 : Strasbourg\n",
      "Found ADP: par - WEAK - DEST\n",
      "Found VERB: passer - WEAK - START\n",
      "Using: par\n",
      "---------------\n",
      "Result trip: ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 11    ***************************\n",
      "result:    ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "exprected: ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux partir de Mulhouse et visiter Paris depuis la destination de Strasbourg\n",
      "Locations found: ['Mulhouse', 'Paris', 'Strasbourg']\n",
      "Token #1 : Mulhouse\n",
      "Found ADP: de - STRONG - START\n",
      "Using: de\n",
      "---------------\n",
      "Token #2 : Paris\n",
      "Found VERB: visiter - STRONG - DEST\n",
      "Using: visiter\n",
      "---------------\n",
      "Token #3 : Strasbourg\n",
      "Found NOUN: destination - WEAK - DEST\n",
      "Using: destination\n",
      "---------------\n",
      "Result trip: ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 12    ***************************\n",
      "result:    ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "exprected: ['Mulhouse', 'Strasbourg', 'Paris']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux prendre le train de Mulhouse à destination de Colmar et Strasbourg\n",
      "Locations found: ['Mulhouse', 'Colmar', 'Strasbourg']\n",
      "Token #1 : Mulhouse\n",
      "Found ADP: de - STRONG - START\n",
      "Using: de\n",
      "---------------\n",
      "Token #2 : Colmar\n",
      "Found NOUN: destination - WEAK - DEST\n",
      "Using: destination\n",
      "---------------\n",
      "Token #3 : Strasbourg\n",
      "Found CCONJ: et - STRONG - DEST\n",
      "Using: et\n",
      "---------------\n",
      "Result trip: ['Mulhouse', 'Colmar', 'Strasbourg']\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 13    ***************************\n",
      "result:    ['Mulhouse', 'Colmar', 'Strasbourg']\n",
      "exprected: ['Mulhouse', 'Colmar', 'Strasbourg']\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je souhaite une pizza napolitaine à Rome\n",
      "Locations found: ['Rome']\n",
      "Cannot parse request or invalid request.\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 14    ***************************\n",
      "result:    None\n",
      "exprected: []\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n",
      "Request: Je veux aller à Lyon\n",
      "Locations found: ['Lyon']\n",
      "Cannot parse request or invalid request.\n",
      "\n",
      "\n",
      "\n",
      "***************************    # 15    ***************************\n",
      "result:    None\n",
      "exprected: []\n",
      "*****************************************************************\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract cities list in the right travel order from the user's request\n",
    "\n",
    "# Spacy documentation: https://spacy.io/usage/linguistic-features\n",
    "# NLP Feature that we use or can be useful:\n",
    "#   - Lemmatization: we use it to avoid defining every possible form of a word when defining our rules\n",
    "#   - PoS Tagging: we use it to detect the function of a word which helps us to choose which rule we apply and reduce the number of checks we need to do\n",
    "#   - Dependency Parsing: we use it to navigate in the sentence between the words that are linked\n",
    "#   - Word Senses: we use it to define our rules that assigns a specific direction and strength to apply to certain words/fixed word groups\n",
    "#   - Constituent Parsing: we currently don't use it, but it might help us improve reliability by splitting sentences into sub-sentences that we can then organize between them\n",
    "\n",
    "\n",
    "class RelationDirection(Enum):\n",
    "    NONE = 1\n",
    "    START = 2\n",
    "    DEST = 3\n",
    "\n",
    "class RelationStrength(Enum):\n",
    "    NONE = 1\n",
    "    WEAK = 2\n",
    "    STRONG = 3\n",
    "\n",
    "\n",
    "class WordSense:\n",
    "    def __init__(self, word: str, direction: RelationDirection, strength: RelationStrength):\n",
    "        self.word = word\n",
    "        self.direction = direction\n",
    "        self.strength = strength\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Word '{self.word}' has a direction of {self.direction.name} and a {self.strength.name} strength.\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Word '{self.word}' has a direction of {self.direction.name} and a {self.strength.name} strength.\"\n",
    "\n",
    "class LinkedWordSense:\n",
    "    def __init__(self, word: str, fixedWord: str, direction: RelationDirection, strength: RelationStrength):\n",
    "        self.word = word\n",
    "        self.fixedWord = fixedWord\n",
    "        self.direction = direction\n",
    "        self.strength = strength\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Words '{self.word}' fixed with '{self.fixedWord}' has a direction of {self.direction.name} and a {self.strength.name} strength.\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Words '{self.word}' fixed with '{self.fixedWord}' has a direction of {self.direction.name} and a {self.strength.name} strength.\"\n",
    "\n",
    "# CCONJ links: 'cc'_child\n",
    "CCONJ_Relation = [\n",
    "    # Start\n",
    "    WordSense(\"depuis\",     RelationDirection.START, RelationStrength.STRONG),\n",
    "    # Destination\n",
    "    WordSense(\"puis\",       RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"et\",         RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"enfin\",      RelationDirection.DEST,  RelationStrength.STRONG)\n",
    "]\n",
    "\n",
    "# NOUN links: 'nmod'_parent\n",
    "NOUN_Relation = [\n",
    "    # Start\n",
    "    WordSense(\"provenance\",     RelationDirection.START, RelationStrength.STRONG),\n",
    "    # Destination\n",
    "    WordSense(\"direction\",      RelationDirection.DEST,  RelationStrength.WEAK),\n",
    "    WordSense(\"destination\",    RelationDirection.DEST,  RelationStrength.WEAK)\n",
    "]\n",
    "\n",
    "# ADP_FIXED has the priority \n",
    "# ADP links: 'case'_child, 'dep'_parent\n",
    "ADP_FIXED_Relation = [\n",
    "    # Start\n",
    "    LinkedWordSense(\"à\",\"partir\",       RelationDirection.START, RelationStrength.STRONG),\n",
    "    LinkedWordSense(\"en\", \"partant\",    RelationDirection.START, RelationStrength.STRONG),\n",
    "    # Destination\n",
    "    LinkedWordSense(\"à\",\"destination\",  RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    LinkedWordSense(\"en\",\"direction\",   RelationDirection.DEST,  RelationStrength.WEAK)\n",
    "]\n",
    "ADP_Relation = [\n",
    "    # Start\n",
    "    WordSense(\"de\",     RelationDirection.START, RelationStrength.STRONG),\n",
    "    WordSense(\"du\",     RelationDirection.START, RelationStrength.STRONG),\n",
    "    WordSense(\"des\",    RelationDirection.START, RelationStrength.STRONG),\n",
    "    WordSense(\"depuis\", RelationDirection.START, RelationStrength.STRONG),\n",
    "    # Destination\n",
    "    WordSense(\"à\",      RelationDirection.DEST,  RelationStrength.WEAK),\n",
    "    WordSense(\"au\",     RelationDirection.DEST,  RelationStrength.WEAK),\n",
    "    WordSense(\"aux\",    RelationDirection.DEST,  RelationStrength.WEAK),\n",
    "    WordSense(\"dans\",   RelationDirection.DEST,  RelationStrength.WEAK),\n",
    "    WordSense(\"en\",     RelationDirection.DEST,  RelationStrength.WEAK),\n",
    "    WordSense(\"par\",    RelationDirection.DEST,  RelationStrength.WEAK) # par : \"passer par Paris\"\n",
    "] \n",
    "\n",
    "# VERB links: 'obl:arg'_parent, 'obl:mod'_parent\n",
    "# \"partir\" is ambiguous: \"partir de ...\" \"partir à ...\"\n",
    "VERB_MARK_Relation = [\n",
    "    WordSense(\"après\",   RelationDirection.START, RelationStrength.WEAK),\n",
    "    WordSense(\"avant\",   RelationDirection.DEST, RelationStrength.STRONG),\n",
    "    WordSense(\"de\",   RelationDirection.START, RelationStrength.STRONG),\n",
    "]\n",
    "VERB_Relation = [\n",
    "    # Start\n",
    "    WordSense(\"décoller\",   RelationDirection.START, RelationStrength.STRONG),\n",
    "    WordSense(\"passer\",     RelationDirection.START, RelationStrength.WEAK),\n",
    "    WordSense(\"être\",       RelationDirection.START, RelationStrength.STRONG),\n",
    "    # Destination\n",
    "    WordSense(\"arriver\",    RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"aller\",      RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"visiter\",    RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"atterrir\",   RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"découvrir\",  RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"voyager\",    RelationDirection.DEST,  RelationStrength.STRONG),\n",
    "    WordSense(\"rendre\",     RelationDirection.DEST,  RelationStrength.STRONG)\n",
    "]\n",
    "\n",
    "def analyseRequest(request):\n",
    "    print(f\"Request: {request}\")\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "    doc = nlp(request)\n",
    "    locations = []\n",
    "    fullTrip = []\n",
    "\n",
    "    # Extract locations\n",
    "    for i in doc.ents:\n",
    "        if i.label_ == 'LOC' or i.label_ == 'GPE': \n",
    "            locations.append(i.text)\n",
    "    print(f\"Locations found: {locations}\")\n",
    "\n",
    "    if len(locations) <= 1:\n",
    "        print(\"Cannot parse request or invalid request.\")\n",
    "    else:\n",
    "        # Get token for each locations\n",
    "        tokens = np.zeros(len(locations), dtype=object)\n",
    "        for i in range(len(locations)):\n",
    "            tokenFound = False\n",
    "            # Priority: PROPN\n",
    "            for token in doc:\n",
    "                if token.pos == PROPN:\n",
    "                    isUsable = True\n",
    "                    for tokenSelected in tokens:\n",
    "                        if type(tokenSelected) != int and tokenSelected == token:\n",
    "                            isUsable = False\n",
    "                    if isUsable:\n",
    "                        if token.text in locations[i]:\n",
    "                            tokens[i] = token\n",
    "                            tokenFound = True\n",
    "                            break\n",
    "\n",
    "            # Secondary: NOUN\n",
    "            if tokenFound == False:\n",
    "                for token in doc:\n",
    "                    if token.pos == NOUN:\n",
    "                        isUsable = True\n",
    "                        for tokenSelected in tokens:\n",
    "                            if type(tokenSelected) != int and tokenSelected == token:\n",
    "                                isUsable = False\n",
    "                        if isUsable:\n",
    "                            if token.text in locations[i]:\n",
    "                                tokens[i] = token\n",
    "                                tokenFound = True\n",
    "                                break\n",
    "\n",
    "            # Failsafe: any (e.g in \"Je veux faire Paris Gare De l'Est Marseille\": Marseille is parsed as a VERB)\n",
    "            if tokenFound == False:\n",
    "                for token in doc:\n",
    "                    isUsable = True\n",
    "                    for tokenSelected in tokens:\n",
    "                        if type(tokenSelected) != int and tokenSelected == token:\n",
    "                            isUsable = False\n",
    "                    if isUsable:\n",
    "                        if token.text in locations[i]:\n",
    "                            tokens[i] = token\n",
    "                            tokenFound = True\n",
    "                            break\n",
    "\n",
    "            # None\n",
    "            if tokenFound == False:\n",
    "                print(f\"Localization {locations[i]} not found\")\n",
    "                tokens[i] = None\n",
    "\n",
    "        # Remove None tokens\n",
    "        tmpTokens = tokens\n",
    "        tokens = [] \n",
    "        for token in tmpTokens: \n",
    "            if token != None : \n",
    "                tokens.append(token)\n",
    "\n",
    "\n",
    "        # Weight tokens to prepare ordering\n",
    "        weighedTokens = np.zeros(len(tokens), dtype=object)\n",
    "        for i in range(len(tokens)):\n",
    "            print(f\"Token #{i+1} : {tokens[i].lemma_}\")\n",
    "            foundWeight = []\n",
    "            parent = tokens[i].head\n",
    "\n",
    "            # CCONJ\n",
    "            for child in tokens[i].children:\n",
    "                if child.pos == CCONJ:\n",
    "                    for ref in CCONJ_Relation:\n",
    "                        if ref.word == child.lemma_:\n",
    "                            print(f\"Found CCONJ: {ref.word} - {ref.strength.name} - {ref.direction.name}\")\n",
    "                            foundWeight.append(ref)\n",
    "                            break\n",
    "\n",
    "            # NOUN\n",
    "            if len(foundWeight) <= 0: # Not prioritary over CCONJ\n",
    "                if parent.pos == NOUN:\n",
    "                    for ref in NOUN_Relation:\n",
    "                        if ref.word == parent.lemma_:\n",
    "                            print(f\"Found NOUN: {ref.word} - {ref.strength.name} - {ref.direction.name}\")\n",
    "                            foundWeight.append(ref)\n",
    "                            break\n",
    "\n",
    "            # ADP_FIXED\n",
    "            if len(foundWeight) <= 0: # Not prioritary over CCONJ and NOUN\n",
    "                for child in tokens[i].children:\n",
    "                    if child.pos == ADP:\n",
    "                        for subChild in child.children:\n",
    "                            if subChild.dep_ == 'fixed':\n",
    "                                for ref in ADP_FIXED_Relation:\n",
    "                                    if ref.word == child.lemma_ and ref.fixedWord == subChild.lemma_:\n",
    "                                        print(f\"Found ADP_FIXED: {ref.word} {ref.fixedWord} - {ref.strength.name} - {ref.direction.name}\")\n",
    "                                        foundWeight.append(ref)\n",
    "                                        break\n",
    "\n",
    "                \n",
    "                    \n",
    "            # ADP\n",
    "            if len(foundWeight) <= 0: # Not prioritary over CCONJ, NOUN and ADP_FIXED\n",
    "                for child in tokens[i].children:\n",
    "                    for ref in ADP_Relation:\n",
    "                        if ref.word == child.lemma_:\n",
    "                            print(f\"Found ADP: {ref.word} - {ref.strength.name} - {ref.direction.name}\")\n",
    "                            foundWeight.append(ref)\n",
    "                            break\n",
    "\n",
    "            # VERB_MARK\n",
    "            if len(foundWeight) <= 1: # Prioritary over CCONJ, NOUN and ADP_FIXED\n",
    "                if parent.pos == VERB:\n",
    "                    for child in parent.children:\n",
    "                        if child.dep_ == 'mark' and child.pos == ADP:\n",
    "                            for ref in VERB_MARK_Relation:\n",
    "                                if ref.word == child.lemma_:\n",
    "                                    print(f\"Found VERB_MARK: {ref.word} - {ref.strength.name} - {ref.direction.name}\")\n",
    "                                    foundWeight.append(ref)\n",
    "                                    break\n",
    "                \n",
    "            # VERB\n",
    "            if len(foundWeight) <= 1: # Prioritary over CCONJ, NOUN, ADP_FIXED and VERB_MARK\n",
    "                for ref in VERB_Relation:\n",
    "                    if ref.word == parent.lemma_:\n",
    "                        print(f\"Found VERB: {ref.word} - {ref.strength.name} - {ref.direction.name}\")\n",
    "                        foundWeight.append(ref)\n",
    "                        break\n",
    "\n",
    "            # Default - Keep position \n",
    "            if len(foundWeight) == 0: # Fallback\n",
    "                print(f\"Using default weight\")\n",
    "                foundWeight.append(WordSense(\"default\", RelationDirection.DEST,  RelationStrength.WEAK))\n",
    "\n",
    "            \n",
    "            # Extract first strong relation\n",
    "            selectedWeight = None\n",
    "            for j in range(len(foundWeight)):\n",
    "                if foundWeight[j].strength == RelationStrength.STRONG:\n",
    "                    selectedWeight = foundWeight[j]\n",
    "                    break\n",
    "            if selectedWeight is None:\n",
    "                selectedWeight = foundWeight[0]\n",
    "\n",
    "            print(f\"Using: {selectedWeight.word}\")\n",
    "            print(\"---------------\")\n",
    "            weighedTokens[i] = (tokens[i], selectedWeight)\n",
    "\n",
    "\n",
    "        # Order tokens\n",
    "        orderedTokens = []\n",
    "        # First pass for direction: START\n",
    "        numberOfStrongStrength = 0\n",
    "        for i in range(len(weighedTokens)):\n",
    "            token, weight = weighedTokens[i]\n",
    "            if weight.direction == RelationDirection.START:\n",
    "                if weight.strength == RelationStrength.STRONG:\n",
    "                    orderedTokens.insert(numberOfStrongStrength, token)\n",
    "                    numberOfStrongStrength = numberOfStrongStrength + 1\n",
    "                else:\n",
    "                    orderedTokens.append(token)\n",
    "        \n",
    "\n",
    "        # Second pass for direction: DEST\n",
    "        numberOfStrongStrength = 0\n",
    "        for i in range(len(weighedTokens)):\n",
    "            token, weight = weighedTokens[i]\n",
    "            if weight.direction == RelationDirection.DEST:\n",
    "                if weight.strength == RelationStrength.STRONG:\n",
    "                    orderedTokens.append(token)\n",
    "                    numberOfStrongStrength = numberOfStrongStrength + 1\n",
    "                else:\n",
    "                    if numberOfStrongStrength == 0:\n",
    "                        orderedTokens.append(token)\n",
    "                    else:\n",
    "                        orderedTokens.insert(len(orderedTokens)-numberOfStrongStrength, token)\n",
    "\n",
    "        # Populate full trip cities list\n",
    "        for token in orderedTokens:\n",
    "            fullTrip.append(token.text)\n",
    "        print(f\"Result trip: {fullTrip}\")\n",
    "\n",
    "        # DEBUG\n",
    "        #for token in doc:\n",
    "        #    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop)\n",
    "        #displacy.serve(doc, style=\"dep\")\n",
    "\n",
    "        return fullTrip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TESTS\n",
    "requests = [\n",
    "    (\"Je veux partir de Mulhouse et visiter Paris depuis Strasbourg\", [\"Mulhouse\", \"Strasbourg\", \"Paris\"]),\n",
    "    (\"J'aimerais aller d'Orléans à Paris puis dans les Vosges\", [\"Orléans\", \"Paris\", \"Vosges\"]),\n",
    "    (\"Je veux aller à Marseille à partir de Lyon\", [\"Lyon\", \"Marseille\"]),\n",
    "    (\"Je veux visiter Paris en partant de Bordeaux et en passant par Nantes\", [\"Bordeaux\", \"Nantes\", \"Paris\"]),\n",
    "    (\"Je veux prendre le train à Mulhouse à destination de Strasbourg\", [\"Mulhouse\", \"Strasbourg\"]),\n",
    "    (\"Strasbourg en provenance de Mulhouse\", [\"Mulhouse\", \"Strasbourg\"]),\n",
    "    (\"Je veux aller de Mulhouse à Strasbourg\", [\"Mulhouse\", \"Strasbourg\"]),\n",
    "    (\"Je veux faire Paris Gare De l'est Marseille\", [\"Paris\", \"Marseille\"]),\n",
    "    (\"Je veux aller à Paris après être allé à Mulhouse depuis Lyon\", [\"Lyon\", \"Mulhouse\", \"Paris\"]),\n",
    "    (\"Paris-Marseille\", [\"Paris\", \"Marseille\"]),\n",
    "    (\"Je suis à Paris et je veux aller à Strasbourg avec mon amis Frank que je récupère à Mulhouse\", [\"Paris\", \"Mulhouse\", \"Strasbourg\"]),\n",
    "    (\"Je veux voyager de Mulhouse pour visiter Paris en passant par Strasbourg\", [\"Mulhouse\", \"Strasbourg\", \"Paris\"]),\n",
    "    (\"Je veux partir de Mulhouse et visiter Paris depuis la destination de Strasbourg\", [\"Mulhouse\", \"Strasbourg\", \"Paris\"]),\n",
    "    (\"Je veux prendre le train de Mulhouse à destination de Colmar et Strasbourg\", [\"Mulhouse\", \"Colmar\", \"Strasbourg\"]),\n",
    "    (\"Je souhaite une pizza napolitaine à Rome\", []),\n",
    "    (\"Je veux aller à Lyon\", [])\n",
    "]\n",
    "\n",
    "def testNLP():\n",
    "    for index in range(len(requests)):\n",
    "        sentence, expectedResult = requests[index]\n",
    "        result = analyseRequest(sentence)\n",
    "        print(f\"\\n\\n\\n***************************    # {index}    ***************************\")\n",
    "        print(f\"result:    {result}\")\n",
    "        print(f\"exprected: {expectedResult}\")\n",
    "        print(\"*****************************************************************\\n\\n\\n\")\n",
    "testNLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting to noise level...\n",
      "Listening...\n"
     ]
    }
   ],
   "source": [
    "# Record user's request and analyse it\n",
    "\n",
    "userRequest = recordUserRequest()\n",
    "fullTrip = analyseRequest(userRequest)\n",
    "\n",
    "if fullTrip is not None:\n",
    "    resultTrips = getBestPathForFullTrip(fullTrip)\n",
    "    print(\"\\n\\n\\nHere is the trip you are asking for: \\n\")\n",
    "    for i in range(len(resultTrips)):\n",
    "        if resultTrips[i].path is not None:\n",
    "            print(f\"#{i+1} - {resultTrips[i]}\")\n",
    "        else:\n",
    "            if resultTrips[i].startStationId is None or resultTrips[i].endStationId is None:\n",
    "                print(f\"#{i+1} - Could not find one or both station of the sub-trip\")\n",
    "            else:\n",
    "                print(f\"#{i+1} - Could not find a path between the both stations\")\n",
    "else:\n",
    "    print(\"\\n\\n\\nSorry, but we cannot answer this request.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adjusting to noise level...\n",
      "Listening...\n",
      "Voice recognition...\n",
      "Parsed: 'une pizza 4 fromages et un smoothie à la banane pour mon ami Patrick s'il vous plaît'\n",
      "Request: une pizza 4 fromages et un smoothie à la banane pour mon ami Patrick s'il vous plaît\n",
      "Locations found: []\n",
      "Cannot parse request or invalid request.\n",
      "\n",
      "\n",
      "\n",
      "Sorry, but we cannot answer this request.\n"
     ]
    }
   ],
   "source": [
    "# Record user's request and analyse it\n",
    "\n",
    "userRequest = recordUserRequest()\n",
    "fullTrip = analyseRequest(userRequest)\n",
    "\n",
    "if fullTrip is not None:\n",
    "    resultTrips = getBestPathForFullTrip(fullTrip)\n",
    "    print(\"\\n\\n\\nHere is the trip you are asking for: \\n\")\n",
    "    for i in range(len(resultTrips)):\n",
    "        if resultTrips[i].path is not None:\n",
    "            print(f\"#{i+1} - {resultTrips[i]}\")\n",
    "        else:\n",
    "            if resultTrips[i].startStationId is None or resultTrips[i].endStationId is None:\n",
    "                print(f\"#{i+1} - Could not find one or both station of the sub-trip\")\n",
    "            else:\n",
    "                print(f\"#{i+1} - Could not find a path between the both stations\")\n",
    "else:\n",
    "    print(\"\\n\\n\\nSorry, but we cannot answer this request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n<html lang=\"fr\">\n    <head>\n        <title>displaCy</title>\n    </head>\n\n    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n<figure style=\"margin-bottom: 6rem\">\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"e6893d10b8ad4cebbae7d6faf9ceca4a-0\" class=\"displacy\" width=\"2325\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Je</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">veux</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">prendre</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">le</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">train</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">de</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Mulhouse</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">à</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">destination</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">de</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Colmar</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">et</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">CCONJ</tspan>\n</text>\n\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">Strasbourg</tspan>\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PROPN</tspan>\n</text>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M385.0,354.0 L393.0,342.0 377.0,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M740.0,354.0 L748.0,342.0 732.0,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-7\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:arg</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-9\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,177.0 1790.0,177.0 1790.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1790.0,354.0 L1798.0,342.0 1782.0,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-10\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M1995,354.0 L1987,342.0 2003,342.0\" fill=\"currentColor\"/>\n</g>\n\n<g class=\"displacy-arrow\">\n    <path class=\"displacy-arc\" id=\"arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-11\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 2145.0,89.5 2145.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n        <textPath xlink:href=\"#arrow-e6893d10b8ad4cebbae7d6faf9ceca4a-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n    </text>\n    <path class=\"displacy-arrowhead\" d=\"M2145.0,354.0 L2153.0,342.0 2137.0,342.0\" fill=\"currentColor\"/>\n</g>\n</svg>\n</figure>\n</body>\n</html></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-58133669b1cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fr_core_news_sm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Je veux prendre le train de Mulhouse à destination de Colmar et Strasbourg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdisplacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dep\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py\u001b[0m in \u001b[0;36mserve\u001b[1;34m(docs, style, page, minify, options, manual, port, host)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminify\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mhttpd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimple_server\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_server\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nUsing the '{}' visualizer\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Serving on http://{}:{} ...\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wsgiref\\simple_server.py\u001b[0m in \u001b[0;36mmake_server\u001b[1;34m(host, port, app, server_class, handler_class)\u001b[0m\n\u001b[0;32m    151\u001b[0m ):\n\u001b[0;32m    152\u001b[0m     \u001b[1;34m\"\"\"Create a new WSGI server listening on `host` and `port` for `app`\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m     \u001b[0mserver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserver_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandler_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[0mserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_app\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mserver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socketserver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, server_address, RequestHandlerClass, bind_and_activate)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbind_and_activate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_activate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\wsgiref\\simple_server.py\u001b[0m in \u001b[0;36mserver_bind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mserver_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;34m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mHTTPServer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_environ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\server.py\u001b[0m in \u001b[0;36mserver_bind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0msocketserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCPServer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfqdn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_port\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetfqdn\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgethostname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[0mhostname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maliases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mipaddrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgethostbyaddr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "doc = nlp(\"Je veux prendre le train de Mulhouse à destination de Colmar et Strasbourg\")\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "a927df1c454baf2e029b41597da70c29fdc6e08f150c40e418cdd087fe40ab12"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}